\documentclass[../../../include/open-logic-chapter]{subfiles}

\begin{document}

\olchapter{ads}{reinforcementlearning}{Lecture IV}

\olsection{Actor Critic methods}
\subsection{Value function}

This is the future rewards starting at s and following $\pi$

\scalebox{1.5}{%
$\textstyle V^{\pi}a( s_t ) = \sum_{t^{\primt} = t}^T \mathbb{E}_{{s}_{t^{\prime}},a_{t^{\prime}} \sim \pi} \left[r(s_{t^{\prime}},a_{t^{\prime}}) \mid s_t \right] $
}

\subsection{Q-function $\mathbb{Q}^{\pi}$}

This is the future rewards starting at s,taking a and following $\pi$

\end{document}
